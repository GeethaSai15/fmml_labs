{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtFpcCblIgYI/+pWPqWv/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeethaSai15/fmml_labs/blob/main/mod1_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting features from data\n",
        "\n",
        "FMML Module 1, Lab 1"
      ],
      "metadata": {
        "id": "MV30uhkH9ZIj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS8RkZ_v9KBz"
      },
      "outputs": [],
      "source": [
        "!pip -q install wikipedia nltk matplotlib plotly pandas\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import wikipedia\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from nltk.util import ngrams\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Features of text\n",
        "\n",
        "Computures can't understand text. They can only process numbers. So, the logical first step in any attempt to analyze text is to convert it into numbers. This process is called **feature extraction** or **vectorization**. In this lab, we will try some simple methods for feature extraction.\n",
        "\n",
        "First, let us download a 2 documents from Wikipedia in two different languages, English and French. We will then extract features from the text in these documents."
      ],
      "metadata": {
        "id": "A7tq1QGz9dsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic1 = \"Giraffe\"\n",
        "topic2 = \"Elephant\"\n",
        "\n",
        "wikipedia.set_lang(\"en\")\n",
        "\n",
        "eng1 = wikipedia.page(topic1).content\n",
        "eng2 = wikipedia.page(topic2).content\n",
        "\n",
        "wikipedia.set_lang(\"fr\")\n",
        "\n",
        "fr1 = wikipedia.page(topic1).content\n",
        "fr2 = wikipedia.page(topic2).content"
      ],
      "metadata": {
        "id": "g2-wrTsE9gTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng2[:500]"
      ],
      "metadata": {
        "id": "Lp9CeMlQ9mty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what the text looks like in French:\n"
      ],
      "metadata": {
        "id": "oTNcdg-K9iln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fr2[:500]"
      ],
      "metadata": {
        "id": "kzKRR4ab9tum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to clean this up a bit. Let us remove all the special characters and keep only 26 letters and space. Note that this will remove accented characters in French also. We are also removing all the numbers and spaces. So this is not an ideal solution."
      ],
      "metadata": {
        "id": "_fPuQtOC91-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup(text):\n",
        "    text = text.lower()  # make it lowercase\n",
        "    text = re.sub(\n",
        "        r\"[^a-z\\s]\", \"\", text\n",
        "    )  # only keep characters in a-z range and whitespaces\n",
        "    return text"
      ],
      "metadata": {
        "id": "aRvs1whq92ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng1 = cleanup(eng1)\n",
        "eng2 = cleanup(eng2)\n",
        "fr1 = cleanup(fr1)\n",
        "fr2 = cleanup(fr2)"
      ],
      "metadata": {
        "id": "TFqEBj4G97O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng2[:500]"
      ],
      "metadata": {
        "id": "21427C9k99dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fr2[:500]"
      ],
      "metadata": {
        "id": "yKP6epRl9_2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us calculate the frequency of the character n-grams. N-grams are groups of characters of size n. A unigram is a single character and a bigram is a group of two characters and so on.\n",
        "\n",
        "Let us count the frequency of each character in a text and plot it in a histogram."
      ],
      "metadata": {
        "id": "owhzVtDi-EPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tuple2string(tup):\n",
        "    # convert a tuple of characters to a string\n",
        "    # ('t', 'h') - > 'th'\n",
        "    st = \"\"\n",
        "    for ii in tup:\n",
        "        st = st + ii\n",
        "    return st\n",
        "\n",
        "\n",
        "def key2string(keys):\n",
        "    # convert a tuple of tuples to a list of strings\n",
        "    # [('t', 'h'), ('h', 'e')] -> ['th', 'he']\n",
        "    # [('t')] - >['t']\n",
        "    return [tuple2string(i) for i in keys]\n",
        "\n",
        "\n",
        "def get_ngram_freq(ngram):\n",
        "    # get the frequency of ngrams\n",
        "    # sort the keys in alphabetic order\n",
        "    keys = key2string(ngram.keys())\n",
        "    values = list(ngram.values())\n",
        "\n",
        "    combined = zip(keys, values)\n",
        "    zipped_sorted = sorted(combined, key=lambda x: x[0])\n",
        "    keys, values = map(list, zip(*zipped_sorted))\n",
        "    return keys, values"
      ],
      "metadata": {
        "id": "FDkmriTo-CFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us compare the histograms of English pages and French pages. Can you spot a difference?"
      ],
      "metadata": {
        "id": "iqbfGcPG-Hsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "unigram_eng1 = Counter(ngrams(eng1, 1))\n",
        "keys, values = get_ngram_freq(unigram_eng1)\n",
        "axs[0].bar(keys, values)\n",
        "axs[0].set_title(\"English 1\")\n",
        "\n",
        "unigram_eng2 = Counter(ngrams(eng2, 1))\n",
        "keys, values = get_ngram_freq(unigram_eng2)\n",
        "axs[1].bar(keys, values)\n",
        "axs[1].set_title(\"English 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KCXvUCu4-NhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "unigram_fr1 = Counter(ngrams(fr1, 1))\n",
        "keys, values = get_ngram_freq(unigram_fr1)\n",
        "axs[0].bar(keys, values)\n",
        "axs[0].set_title(\"French 1\")\n",
        "\n",
        "unigram_fr2 = Counter(ngrams(fr2, 1))\n",
        "keys, values = get_ngram_freq(unigram_fr2)\n",
        "axs[1].bar(keys, values)\n",
        "axs[1].set_title(\"French 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RaDVeBmj-QPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the unigrams for French and English are very similar. So this is not a good feature if we want to distinguish between English and French. Let us look at bigrams.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fl1qemWz-VhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "bigram_eng1 = Counter(ngrams(eng1, 2))\n",
        "keys, values = get_ngram_freq(bigram_eng1)\n",
        "axs[0, 0].bar(keys, values)\n",
        "axs[0, 0].set_title(\"English 1\")\n",
        "\n",
        "bigram_eng2 = Counter(ngrams(eng2, 2))\n",
        "keys, values = get_ngram_freq(bigram_eng2)\n",
        "axs[0, 1].bar(keys, values)\n",
        "axs[0, 1].set_title(\"English 2\")\n",
        "\n",
        "bigram_fr1 = Counter(ngrams(fr1, 2))\n",
        "keys, values = get_ngram_freq(bigram_fr1)\n",
        "axs[1, 0].bar(keys, values)\n",
        "axs[1, 0].set_title(\"French 1\")\n",
        "\n",
        "bigram_fr2 = Counter(ngrams(fr2, 2))\n",
        "keys, values = get_ngram_freq(bigram_fr2)\n",
        "axs[1, 1].bar(keys, values)\n",
        "axs[1, 1].set_title(\"French 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p2jqTkxF-WOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to visualize bigrams is to use a 2-dimensional graph."
      ],
      "metadata": {
        "id": "k1pL8-Bs-gYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_2D_ngram_freq(ngram):\n",
        "    freq = np.zeros((26, 26))\n",
        "    for ii in range(26):\n",
        "        for jj in range(26):\n",
        "            freq[ii, jj] = ngram[(chr(ord(\"a\") + ii), chr(ord(\"a\") + jj))]\n",
        "    return freq"
      ],
      "metadata": {
        "id": "uPP5ePYu-g6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "bigram_eng1_freq = get_2D_ngram_freq(bigram_eng1)\n",
        "fig.colorbar(axs[0, 0].imshow(bigram_eng1_freq, cmap=\"hot\"), ax=axs[0, 0])\n",
        "axs[0, 0].set_title(\"English 1\")\n",
        "\n",
        "bigram_eng2_freq = get_2D_ngram_freq(bigram_eng2)\n",
        "fig.colorbar(axs[0, 1].imshow(bigram_eng2_freq, cmap=\"hot\"), ax=axs[0, 1])\n",
        "axs[0, 1].set_title(\"English 2\")\n",
        "\n",
        "bigram_fr1_freq = get_2D_ngram_freq(bigram_fr1)\n",
        "fig.colorbar(axs[1, 0].imshow(bigram_fr1_freq, cmap=\"hot\"), ax=axs[1, 0])\n",
        "axs[1, 0].set_title(\"French 1\")\n",
        "\n",
        "bigram_fr2_freq = get_2D_ngram_freq(bigram_fr2)\n",
        "fig.colorbar(axs[1, 1].imshow(bigram_fr2_freq, cmap=\"hot\"), ax=axs[1, 1])\n",
        "axs[1, 1].set_title(\"French 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FFikwKEa-kRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us look at the top 10 ngrams for each text."
      ],
      "metadata": {
        "id": "U5m-hMiO-ocf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ind2tup(ind):\n",
        "    ind = int(ind)\n",
        "    i = int(ind / 26)\n",
        "    j = int(ind % 26)\n",
        "    return (chr(ord(\"a\") + i), chr(ord(\"a\") + j))\n",
        "\n",
        "\n",
        "def ShowTopN(bifreq, n=10):\n",
        "    f = bifreq.flatten()\n",
        "    arg = np.argsort(-f)\n",
        "    for ii in range(n):\n",
        "        print(f\"{ind2tup(arg[ii])} : {f[arg[ii]]}\")"
      ],
      "metadata": {
        "id": "-HfQEmrP-o3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEnglish 1:\")\n",
        "ShowTopN(bigram_eng1_freq)\n",
        "\n",
        "print(\"\\nEnglish 2:\")\n",
        "ShowTopN(bigram_eng2_freq)\n",
        "\n",
        "print(\"\\nFrench 1:\")\n",
        "ShowTopN(bigram_fr1_freq)\n",
        "\n",
        "print(\"\\nFrench 2:\")\n",
        "ShowTopN(bigram_fr2_freq)"
      ],
      "metadata": {
        "id": "f0xiyMAv-sV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the bigrams are similar across different topics but different across languages. Thus, the bigram frequency is a good feature for distinguishing languages, but not for distinguishing topics.\n",
        "\n",
        "Thus, we were able to convert a many-dimensional input (the text) to 26 dimesions (unigrams) or 26*26 dimensions (bigrams).\n",
        "\n",
        "A few ways to explore:\n",
        "\n",
        "Try with different languages.\n",
        "The topics we used are quite similar, wikipedia articles of 'elephant' and 'giraffe'. What happens if we use very different topics? What if we use text from another source than Wikipedia?\n",
        "How can we use and visualize trigrams and higher n-grams?"
      ],
      "metadata": {
        "id": "tAXpifOV-zgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: Try to extract trigrams and visualize the top 10 trigrams for each text"
      ],
      "metadata": {
        "id": "enskn0Gw-93d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: Written numbers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FIafX5mp_ARz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've seen how to extract features from text. Now let us see how to extract features from images. We will use the MNIST dataset which contains images of handwritten numbers. Each image is represented in a 28*28 array. Let us see if we can extract some simple features from these images which can help us distinguish between the digits."
      ],
      "metadata": {
        "id": "g2XGChp4_Ktd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ],
      "metadata": {
        "id": "-CTokXV5-u5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract a subset of the data for our experiment:"
      ],
      "metadata": {
        "id": "2N2cUdgk_P9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no1 = train_X[train_y == 1, :, :]\n",
        "no0 = train_X[train_y == 0, :, :]"
      ],
      "metadata": {
        "id": "E0fPsm_w_Qe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us visualize a few images here:"
      ],
      "metadata": {
        "id": "98OT481U_UXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 5, figsize=(15, 5))\n",
        "\n",
        "for ii in range(5):\n",
        "    axs[0, ii].imshow(no0[ii, :, :])\n",
        "\n",
        "for ii in range(5):\n",
        "    axs[1, ii].imshow(no1[ii, :, :])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aXg4c8ph_Ssy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us start with a simple feature: the sum of all pixels. Let's see how good this feature is."
      ],
      "metadata": {
        "id": "BKFbcKk8_juV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum1 = np.sum(no1 > 0, (1, 2))  # threshold before adding up\n",
        "sum0 = np.sum(no0 > 0, (1, 2))"
      ],
      "metadata": {
        "id": "5X09itfj_nJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let us visualize how good this feature is: (X-axis is mean, y-axis is the digit)"
      ],
      "metadata": {
        "id": "3qflPUPS_nq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(sum1, alpha=0.7)\n",
        "plt.hist(sum0, alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WZVu4hha_plf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can already see that this feature separates the two classes quite well.\n",
        "\n",
        "Let us look at another, more complicated feature. We will count the number black pixels that are surrounded on four sides by non-black pixels, or \"hole pixels\"."
      ],
      "metadata": {
        "id": "R7kGalIw_t-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cumArray(img):\n",
        "    img2 = img.copy()\n",
        "    for ii in range(1, img2.shape[1]):\n",
        "        img2[ii, :] = (\n",
        "            img2[ii, :] + img2[ii - 1, :]\n",
        "        )  # for every row, add up all the rows above it.\n",
        "    img2 = img2 > 0\n",
        "    return img2\n",
        "\n",
        "\n",
        "def getHolePixels(img):\n",
        "    im1 = cumArray(img)\n",
        "    im2 = np.rot90(\n",
        "        cumArray(np.rot90(img)), 3\n",
        "    )  # rotate and cumulate it again for differnt direction\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    hull = (\n",
        "        im1 & im2 & im3 & im4\n",
        "    )  # this will create a binary image with all the holes filled in.\n",
        "    # remove the original digit to leave behind the holes\n",
        "    hole = hull & ~(img > 0)\n",
        "    return hole"
      ],
      "metadata": {
        "id": "ilKKpybv_udh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize a few. First row has the original zero number images and the second row has the hole pixels. Thrid row has original one number images and the last row has corresponding hole pixels which are non-existent, as expected."
      ],
      "metadata": {
        "id": "Nms1S8aa_3Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_ids = [12, 236, 345, 435, 512]\n",
        "fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
        "\n",
        "for ii, idx in enumerate(img_ids):\n",
        "    axs[0, ii].imshow(no0[idx, :, :])\n",
        "    axs[1, ii].imshow(getHolePixels(no0[idx, :, :]))\n",
        "    axs[2, ii].imshow(no1[idx, :, :])\n",
        "    axs[3, ii].imshow(getHolePixels(no1[idx, :, :]))"
      ],
      "metadata": {
        "id": "djZnbbHi_4Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us plot the number of hole pixels and see how this feature behaves"
      ],
      "metadata": {
        "id": "j_QJjAzk_--h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hole1 = np.array([getHolePixels(i).sum() for i in no1])\n",
        "hole0 = np.array([getHolePixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hole1, alpha=0.7)\n",
        "plt.hist(hole0, alpha=0.7)"
      ],
      "metadata": {
        "id": "VpiAgOunAC08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This feature works even better to distinguish between one and zero.\n",
        "\n",
        "Now let us try the number of pixels in the 'hull' or the number with the holes filled in:"
      ],
      "metadata": {
        "id": "uQjGNaKjADfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getHullPixels(img):\n",
        "    im1 = cumArray(img)\n",
        "    im2 = np.rot90(\n",
        "        cumArray(np.rot90(img)), 3\n",
        "    )  # rotate and cumulate it again for differnt direction\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    hull = (\n",
        "        im1 & im2 & im3 & im4\n",
        "    )  # this will create a binary image with all the holes filled in.\n",
        "    return hull"
      ],
      "metadata": {
        "id": "8jnemLF-AF-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_ids = [12, 236, 345, 435, 512]\n",
        "fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
        "\n",
        "for ii, idx in enumerate(img_ids):\n",
        "    axs[0, ii].imshow(no0[idx, :, :])\n",
        "    axs[1, ii].imshow(getHullPixels(no0[idx, :, :]))\n",
        "    axs[2, ii].imshow(no1[idx, :, :])\n",
        "    axs[3, ii].imshow(getHullPixels(no1[idx, :, :]))"
      ],
      "metadata": {
        "id": "AELBfLlPALfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the number of hull pixels versus the digit:"
      ],
      "metadata": {
        "id": "EgK5v92lANR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hull1 = np.array([getHullPixels(i).sum() for i in no1])\n",
        "hull0 = np.array([getHullPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hull1, alpha=0.7)\n",
        "plt.hist(hull0, alpha=0.7)"
      ],
      "metadata": {
        "id": "3IEq8va4APq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try one more feature, where we look at the number of boundary pixels in each image."
      ],
      "metadata": {
        "id": "K4ifoZxyASmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minus(a, b):\n",
        "    return a & ~b\n",
        "\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "    img = img.copy() > 0  # binarize the image\n",
        "    rshift = np.roll(img, 1, 1)\n",
        "    lshift = np.roll(img, -1, 1)\n",
        "    ushift = np.roll(img, -1, 0)\n",
        "    dshift = np.roll(img, 1, 0)\n",
        "    boundary = (\n",
        "        minus(img, rshift)\n",
        "        | minus(img, lshift)\n",
        "        | minus(img, ushift)\n",
        "        | minus(img, dshift)\n",
        "    )\n",
        "    return boundary"
      ],
      "metadata": {
        "id": "2tZW7lclAWM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_ids = [12, 236, 345, 435, 512]\n",
        "fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
        "\n",
        "for ii, idx in enumerate(img_ids):\n",
        "    axs[0, ii].imshow(no0[idx, :, :])\n",
        "    axs[1, ii].imshow(getBoundaryPixels(no0[idx, :, :]))\n",
        "    axs[2, ii].imshow(no1[idx, :, :])\n",
        "    axs[3, ii].imshow(getBoundaryPixels(no1[idx, :, :]))"
      ],
      "metadata": {
        "id": "skA6DJ7lAajX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bound1 = np.array([getBoundaryPixels(i).sum() for i in no1])\n",
        "bound0 = np.array([getBoundaryPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(bound1, alpha=0.7)\n",
        "plt.hist(bound0, alpha=0.7)"
      ],
      "metadata": {
        "id": "Sb3BP7sqAdCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What will happen if we plot two features together?"
      ],
      "metadata": {
        "id": "h2VWktlFAfrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "axs[0].scatter(sum0, hull0, alpha=0.1)\n",
        "axs[0].scatter(sum1, hull1, alpha=0.1)\n",
        "axs[0].set_xlabel(\"Sum\")\n",
        "axs[0].set_ylabel(\"Hull\")\n",
        "axs[0].legend([\"0\", \"1\"])\n",
        "\n",
        "axs[1].scatter(sum0, hole0, alpha=0.1)\n",
        "axs[1].scatter(sum1, hole1, alpha=0.1)\n",
        "axs[1].set_xlabel(\"Sum\")\n",
        "axs[1].set_ylabel(\"Hole\")\n",
        "axs[1].legend([\"0\", \"1\"])\n",
        "\n",
        "axs[2].scatter(bound0, hole0, alpha=0.1)\n",
        "axs[2].scatter(bound1, hole1, alpha=0.1)\n",
        "axs[2].set_xlabel(\"Boundary\")\n",
        "axs[2].set_ylabel(\"Hole\")\n",
        "axs[2].legend([\"0\", \"1\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w1ccYqQXAkEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us try plotting 3 features together."
      ],
      "metadata": {
        "id": "P5cv48m8AmwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "axs[0].scatter(sum0, hull0, alpha=0.1)\n",
        "axs[0].scatter(sum1, hull1, alpha=0.1)\n",
        "axs[0].set_xlabel(\"Sum\")\n",
        "axs[0].set_ylabel(\"Hull\")\n",
        "axs[0].legend([\"0\", \"1\"])\n",
        "\n",
        "axs[1].scatter(sum0, hole0, alpha=0.1)\n",
        "axs[1].scatter(sum1, hole1, alpha=0.1)\n",
        "axs[1].set_xlabel(\"Sum\")\n",
        "axs[1].set_ylabel(\"Hole\")\n",
        "axs[1].legend([\"0\", \"1\"])\n",
        "\n",
        "axs[2].scatter(bound0, hole0, alpha=0.1)\n",
        "axs[2].scatter(bound1, hole1, alpha=0.1)\n",
        "axs[2].set_xlabel(\"Boundary\")\n",
        "axs[2].set_ylabel(\"Hole\")\n",
        "axs[2].legend([\"0\", \"1\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6CZVukDKApjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us try plotting 3 features together."
      ],
      "metadata": {
        "id": "N0VEFXvhArvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cl1 = [\"class 1\"] * len(sum1)\n",
        "cl0 = [\"class 0\"] * len(sum0)\n",
        "df = pd.DataFrame(\n",
        "    list(\n",
        "        zip(\n",
        "            np.concatenate((hole0, hole0)),\n",
        "            np.concatenate((sum1, sum0)),\n",
        "            np.concatenate((bound1, bound0)),\n",
        "            np.concatenate((cl1, cl0)),\n",
        "        )\n",
        "    ),\n",
        "    columns=[\"Hole\", \"Sum\", \"Boundary\", \"Class\"],\n",
        ")\n",
        "df.head()\n",
        "fig = px.scatter_3d(df, x=\"Hole\", y=\"Sum\", z=\"Boundary\",\n",
        "                    color=\"Class\", opacity=0.1)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "BA39sn5eAw8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to explore the above graph with your mouse.\n",
        "\n",
        "We extracted four features from a 28*28 dimensional image.\n",
        "\n",
        "Some questions to explore:\n",
        "\n",
        "\n",
        "1.   Which is the best combination of features?\n",
        "2.   How would you test or visualize four or more features?\n",
        "3.  Can you come up with your own features?\n",
        "4.  Will these features work for different classes other than 0 and 1?\n",
        "5.  What will happen if we take more that two classes at a time?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-0z38XylAzTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: Remember we took a subset of only the first two numbers in MNIST? Include 5 or more numbers now and try to visualise which feature works best when multiple numbers are involved. Brownie points if you use all numbers :)"
      ],
      "metadata": {
        "id": "4AffeKJaA6Ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.   Which is the best combination of features?**"
      ],
      "metadata": {
        "id": "xZFR8QVZBBwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best combination of features depends on your specific task, such as classification or regression, and the dataset's characteristics. To determine the best combination:\n",
        "\n",
        "Feature Importance: Use techniques like feature importance scores from models (e.g., Random Forests) or statistical tests (e.g., ANOVA, chi-square tests) to assess the relevance of each feature.\n",
        "\n",
        "Performance Metrics: Evaluate combinations based on performance metrics such as accuracy, precision, recall, or F1-score. Techniques like cross-validation can help ensure that the feature set generalizes well.\n",
        "\n",
        "Dimensionality Reduction: Techniques like Principal Component Analysis (PCA) or Linear Discriminant Analysis (LDA) can help identify important features by reducing dimensionality while retaining variance.\n",
        "\n",
        "Experimentation: Experiment with different combinations of features and assess their impact on model performance. Automated feature selection techniques like Recursive Feature Elimination (RFE) can also be useful."
      ],
      "metadata": {
        "id": "0LZGEWyNBzEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. How would you test or visualize four or more features?**"
      ],
      "metadata": {
        "id": "Sm8CPszKB5T8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test and visualize multiple features:\n",
        "\n",
        "Pairwise Plots: For a small number of features (e.g., four), you can use pairwise plots (scatterplot matrices) to visualize relationships between each pair of features.\n",
        "\n",
        "Dimensionality Reduction: Use techniques like PCA, t-SNE, or UMAP to reduce the dimensionality of your features to 2D or 3D for visualization. This helps to see how features interact and group together.\n",
        "\n",
        "Feature Importance Visualization: Plot feature importance scores to see which features contribute the most to your model.\n",
        "\n",
        "Correlation Heatmap: Create a heatmap of the feature correlation matrix to understand relationships and potential redundancies among features."
      ],
      "metadata": {
        "id": "WVyylR4ICDsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.  Can you come up with your own features?**"
      ],
      "metadata": {
        "id": "3ysPuuTlCH1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, creating your own features can be valuable:\n",
        "\n",
        "Domain Knowledge: Use domain-specific knowledge to create features that might capture important aspects of the data not covered by the original features. For example, in image analysis, you could create features based on texture, edge density, or color histograms.\n",
        "\n",
        "Feature Engineering Techniques: Create new features by combining existing ones (e.g., ratios, differences) or applying transformations (e.g., log transformations, polynomial features).\n",
        "\n",
        "Manual Design: For image data, you could design features based on specific patterns or shapes (e.g., edge detection, histogram of gradients)."
      ],
      "metadata": {
        "id": "l6ZAuoYtCVkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Will these features work for different classes other than 0 and 1?**"
      ],
      "metadata": {
        "id": "QMmRx3PoCZqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The effectiveness of features can vary with different classes:\n",
        "\n",
        "Feature Generalization: Features that work well for binary classification might not be as effective for multi-class classification, as the decision boundaries and distributions change with more classes.\n",
        "\n",
        "Feature Scalability: Ensure that your features are scalable and informative across different classes. Techniques like class-wise feature analysis can help understand feature relevance for each class.\n",
        "\n",
        "Model Adaptation: Adapt your model and feature selection process for multi-class problems, potentially using models designed for multi-class classification or adjusting the feature set accordingly."
      ],
      "metadata": {
        "id": "cRJ5mIxhCffl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What will happen if we take more than two classes at a time?**"
      ],
      "metadata": {
        "id": "dbJBIGrWCilQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with more than two classes:\n",
        "\n",
        "Increased Complexity: The classification problem becomes more complex, requiring models that can handle multi-class classification. Evaluation metrics should be adjusted accordingly (e.g., using macro-averaged precision, recall, and F1-score).\n",
        "\n",
        "Class Imbalance: Be mindful of class imbalances, which can affect model performance. Techniques like class weighting or oversampling/undersampling might be necessary.\n",
        "\n",
        "Feature Discriminability: Ensure that your features remain discriminative and informative across all classes. Feature selection and dimensionality reduction may help to maintain or improve performance.\n",
        "\n",
        "Model Adjustment: You might need to use multi-class classifiers (e.g., Softmax regression, multiclass SVM) or adjust the architecture of your models (e.g., neural networks) to handle the increased number of classes."
      ],
      "metadata": {
        "id": "An8xG0DQCmsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Remember we took a subset of only the first two numbers in MNIST? Include 5 or more numbers now and try to visualise which feature works best when multiple numbers are involved. Brownie points if you use all numbers :)**"
      ],
      "metadata": {
        "id": "kkpXtAWPCqEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data, mnist.target.astype(int)\n",
        "\n",
        "# Select only the digits 0-4\n",
        "mask = np.isin(y, [0, 1, 2, 3, 4])\n",
        "X_subset = X[mask]\n",
        "y_subset = y[mask]\n"
      ],
      "metadata": {
        "id": "FYjc5kChC2lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming features are stored in a DataFrame\n",
        "features_df = pd.DataFrame({\n",
        "    'Feature1': feature1_values,\n",
        "    'Feature2': feature2_values,\n",
        "    'Feature3': feature3_values,\n",
        "    'Feature4': feature4_values,\n",
        "    'Label': y_subset\n",
        "})\n",
        "\n",
        "# Pairplot for visualization\n",
        "sns.pairplot(features_df, hue='Label', palette='tab10')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NK8LCT-7DHzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Combine features into a single matrix\n",
        "features_matrix = np.column_stack([feature1_values, feature2_values, feature3_values, feature4_values])\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(features_matrix)\n",
        "\n",
        "# t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_result = tsne.fit_transform(features_matrix)\n",
        "\n",
        "# Plot PCA result\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=y_subset, cmap='tab10')\n",
        "plt.title('PCA of Features')\n",
        "plt.colorbar(label='Digit')\n",
        "\n",
        "# Plot t-SNE result\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=y_subset, cmap='tab10')\n",
        "plt.title('t-SNE of Features')\n",
        "plt.colorbar(label='Digit')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3YUQsXbGDLrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(features_matrix, y_subset)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(features_matrix)\n",
        "print(classification_report(y_subset, y_pred))\n"
      ],
      "metadata": {
        "id": "BZIN7IuQDOK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select all digits\n",
        "mask_all = np.isin(y, np.arange(10))\n",
        "X_all = X[mask_all]\n",
        "y_all = y[mask_all]\n"
      ],
      "metadata": {
        "id": "3xoefPhODOtK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}